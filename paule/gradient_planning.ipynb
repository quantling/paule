{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import paule\n",
    "import util\n",
    "from util import (speak, normalize_cp, inv_normalize_cp, normalize_mel_librosa, inv_normalize_mel_librosa, stereo_to_mono, librosa_melspec, pad_same_to_even_seq_length, RMSELoss, mel_to_sig, pad_batch_online)\n",
    "from models import *\n",
    "from matplotlib import cm\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "DIR = os.getcwd()\n",
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"\"\n",
    "RESULT_DICT = \"\"\n",
    "SAVE_DICT = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Paule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add continue data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_pickle(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23082022)\n",
    "valid_sample = random.sample(range(len(valid)),12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_data = valid.iloc[valid_sample][[\"vector\",\"cp_norm\",\"melspec_norm_synthesized\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_data[\"segment_data\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paule_model = paule.Paule(use_somatosensory_feedback=False,continue_data=continue_data,device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_pickle(DATA_DIR + \"lexical_embedding_vectors.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle(DATA_DIR + \"common_voice_geco_words_test_subset_slim_prot4.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flac Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in test_data.iterrows():\n",
    "    sr = 48000\n",
    "    sig = row.wav_rec\n",
    "    file_name = row.file_name\n",
    "    label = row.label\n",
    "    \n",
    "    path = RESULT_DICT + label + \"/\"\n",
    "    if os.path.isdir(path):\n",
    "        file = path +  file_name + \"_\" + label + \".flac\"\n",
    "        if os.path.isfile(file):\n",
    "            j = 1\n",
    "            while os.path.isfile(file): \n",
    "                file = path +  file_name + \"_\" + label + \"%d.flac\" % j\n",
    "                j+=1\n",
    "        sf.write(file ,sig, sr)\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        sf.write(path +  file_name + \"_\" + label + \".flac\" ,sig, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shuffle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for dic in os.listdir(RESULT_DICT):\n",
    "    if (\".DS_Store\" in dic) or (\"results\" in dic) : # .DS_Store stores custom attributes of its containing folder in macOS\n",
    "        continue\n",
    "    else:\n",
    "        if not os.path.isdir(os.path.join(SAVE_DICT, dic)):\n",
    "            os.mkdir(os.path.join(SAVE_DICT, dic))\n",
    "        path = os.path.join(RESULT_DICT, dic)\n",
    "        for file in os.listdir(path):\n",
    "            if (\".DS_Store\" in file) or (\"._\" in file) or \".flac\" not in file:\n",
    "                continue\n",
    "            else:\n",
    "                file = os.path.join(path,file)\n",
    "                files.append(file)\n",
    "random.seed(30112021)\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omit already planned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_planned_files = []\n",
    "for dic in os.listdir(SAVE_DICT):\n",
    "    if \".DS_Store\" in dic:\n",
    "        continue\n",
    "    else:\n",
    "        path = os.path.join(SAVE_DICT,dic)\n",
    "        if os.path.isdir(path):\n",
    "            for file in os.listdir(path):\n",
    "                if \"planned\" in file and \".flac\" in file and not \"best\" in file: \n",
    "                    planned_file = \"_\".join(file.split(\"_\")[:-1]) + \".flac\" \n",
    "                    already_planned_files.append(planned_file)\n",
    "\n",
    "unplanned_files = [file for file in files if file.split(\"/\")[-1] not in already_planned_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predictive model already used and further learned during planning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pred_model and pred_optimizer\n",
    "pred_model = torch.load(\"\", map_location=DEVICE)\n",
    "optimizer = torch.load(\"\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load inv_model and inv_optimizer\n",
    "inv_model = torch.load(\"\", map_location=DEVICE)\n",
    "inv_optimizer = torch.load(\"\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tube_model and tube_optimizer\n",
    "tube_model = torch.load(\"\", map_location=DEVICE)\n",
    "tube_optimizer = torch.load(\"\", map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paule_model.pred_model = pred_model\n",
    "paule_model.pred_optimizer = optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paule_model.inv_model = inv_model\n",
    "paule_model.inv_optimizer = inv_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paule_model.tube_model = tube_model\n",
    "paule_model.tube_optimizer = tube_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Planning and store results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize_title = 35\n",
    "fontsize_x = 30\n",
    "fontsize_y = 30\n",
    "fontsize_params = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_learning_inv = True\n",
    "for i, file in enumerate(unplanned_files):\n",
    "    i += len(already_planned_files)\n",
    "    target_acoustic = file #path + \"/\" + file\n",
    "    label = file.split(\"/\")[-1].split(\"_\")[-1][:-5]\n",
    "    target_semvec = vectors[vectors.label == label].vector.iloc[0]\n",
    "    \n",
    "    save_file = f\"{SAVE_DICT}/{os.path.dirname(file).split('/')[-1]}/{os.path.basename(file)[:-5]}\"\n",
    "    \n",
    "    results = paule_model.plan_resynth(learning_rate_planning=0.01,\n",
    "            learning_rate_learning=0.001,\n",
    "            learning_rate_learning_inv=0.001,\n",
    "            target_acoustic=target_acoustic,\n",
    "            target_semvec=target_semvec,\n",
    "            initialize_from=\"acoustic\",\n",
    "            objective=\"acoustic\",\n",
    "            n_outer=10, n_inner=25,\n",
    "            continue_learning=True,\n",
    "            continue_learning_inv=continue_learning_inv,\n",
    "            add_training_data_pred=False,\n",
    "            add_training_data_inv=True,\n",
    "            log_ii=1,\n",
    "            log_semantics=True,\n",
    "            n_batches=3, batch_size=8, n_epochs=10,\n",
    "            log_gradients=False,\n",
    "            plot=save_file, \n",
    "            seed=None,\n",
    "            verbose=True)\n",
    "    \n",
    "    # save model and optimizer\n",
    "    torch.save(paule_model.pred_model, f\"{save_file}_{str(i)}_pred_model.pt\")\n",
    "    torch.save(paule_model.pred_optimizer, f\"{save_file}_{str(i)}_pred_optimizer.pt\")\n",
    "    \n",
    "    if continue_learning_inv:\n",
    "        torch.save(paule_model.inv_model, f\"{save_file}_{str(i)}_inv_model.pt\")\n",
    "        torch.save(paule_model.inv_optimizer, f\"{save_file}_{str(i)}_inv_optimizer.pt\")\n",
    "    \n",
    "\n",
    "    # save results without model and optimizer\n",
    "    with open(f\"{save_file}.pkl\", 'wb') as pfile:\n",
    "        pickle.dump(results, pfile)\n",
    "        \n",
    "    # save continue data if used\n",
    "    if not paule_model.continue_data is None:\n",
    "        with open(f\"{SAVE_DICT}/continue_data.pkl\", 'wb') as pfile:\n",
    "            pickle.dump(paule_model.continue_data, pfile)\n",
    "    \n",
    "    \n",
    "    # save best synthesis acoustic\n",
    "    with open(f\"{save_file}_best_synthesis_acoustic.pkl\", 'wb') as pfile:\n",
    "        pickle.dump(paule_model.best_synthesis_acoustic, pfile)\n",
    "    pfile.close()\n",
    "    \n",
    "    prod_sig = paule_model.best_synthesis_acoustic.prod_sig\n",
    "    sf.write(save_file + \"_planned_best_acoustic.flac\", prod_sig, 44100)\n",
    "    del prod_sig\n",
    "    \n",
    "    if paule_model.best_synthesis_semantic:\n",
    "        # save results without model and optimizer\n",
    "        with open(f\"{save_file}_best_synthesis_semantic.pkl\", 'wb') as pfile:\n",
    "            pickle.dump(paule_model.best_synthesis_semantic, pfile)\n",
    "        pfile.close()\n",
    "        \n",
    "        prod_sig = paule_model.best_synthesis_semantic.prod_sig\n",
    "        sf.write(save_file + \"_planned_best_semantic.flac\", prod_sig, 44100)\n",
    "        del prod_sig\n",
    "    \n",
    "    if paule_model.use_somatosensory_feedback:\n",
    "        with open(f\"{save_file}_best_synthesis_somatosensory.pkl\", 'wb') as pfile:\n",
    "            pickle.dump(paule_model.best_synthesis_somatosensory, pfile)\n",
    "        pfile.close()\n",
    "        \n",
    "        prod_sig = paule_model.best_synthesis_somatosensory.prod_sig\n",
    "        sf.write(save_file + \"_planned_best_somatosensory.flac\", prod_sig, 44100)\n",
    "        del prod_sig\n",
    "\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    # save initial and planned flac\n",
    "    prod_sr = results.prod_sr\n",
    "    sig_initial = results.initial_sig\n",
    "    sf.write(save_file + \"_initial.flac\", sig_initial, prod_sr)\n",
    "    prod_sig = results.prod_sig\n",
    "    sf.write(save_file + \"_planned.flac\", prod_sig, prod_sr)\n",
    "\n",
    "    # save svgs\n",
    "    planned_cp = results.planned_cp\n",
    "    path = save_file + '_svgs/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    util.export_svgs(util.inv_normalize_cp(planned_cp), path=path)\n",
    "    \n",
    "    # save svgs initial \n",
    "    initial_cp = results.initial_cp\n",
    "    path = save_file + '_svgs_initial/'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    util.export_svgs(util.inv_normalize_cp(initial_cp), path=path)\n",
    "\n",
    "    # ffmpeg -r 80 -width 600 -i tract%05d.svg -i planned_0.flac planned_0.mp4\n",
    "    # /usr/bin/ffmpeg -r 80 -width 600 -i /home/tino/Documents/phd/projects/paule/results/000003-Wissenschaft_svgs/tract%05d.svg -i results/000003-Wissenschaft_planned.flac planned.mp4\n",
    "\n",
    "\n",
    "    # save loss plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 8), facecolor=\"white\")\n",
    "    ax.plot(results.planned_loss_steps, label=\"planned loss\", c=\"C0\")\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"{save_file}_loss.png\")\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 8), facecolor=\"white\")\n",
    "    ax.plot(results.prod_loss_steps, label=\"produced mel loss\", c=\"C1\")\n",
    "    ax.plot(results.planned_mel_loss_steps, label=\"planned mel loss\", c=\"C0\")\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"{save_file}_loss_mel.png\")\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    # save subloss plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 8), facecolor=\"white\")\n",
    "    ax.plot(results.vel_loss_steps, label=\"vel loss\", c=\"C2\")\n",
    "    ax.plot(results.jerk_loss_steps, label=\"jerk loss\", c=\"C3\")\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"{save_file}_loss_subloss.png\")\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "    # save semvec loss plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 8), facecolor=\"white\")\n",
    "    ax.plot(results.pred_semvec_loss_steps, label=\"planned semvec loss\", c=\"C0\")\n",
    "    ax.plot(results.prod_semvec_loss_steps, label=\"produced semvec loss\", c=\"C1\")\n",
    "    ax.legend()\n",
    "    fig.savefig(f\"{save_file}_loss_semvec.png\")\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    if paule_model.use_somatosensory_feedback:\n",
    "        # save tube loss plot\n",
    "        fig, ax = plt.subplots(figsize=(15, 8), facecolor=\"white\")\n",
    "        ax.plot(results.prod_tube_loss_steps, label=\"produced tube loss\", c=\"C0\")\n",
    "        ax.legend()\n",
    "        fig.savefig(f\"{save_file}_loss_tube.png\")\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(15, 8), facecolor=\"white\")\n",
    "        ax.plot(results.prod_tube_mel_loss_steps, label=\"produced tube mel loss\", c=\"C1\")\n",
    "        ax.plot(results.pred_tube_mel_loss_steps, label=\"planned tube mel loss\", c=\"C0\")\n",
    "        ax.legend()\n",
    "        fig.savefig(f\"{save_file}_loss_tube_mel.png\")\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(15, 8), facecolor=\"white\")\n",
    "        ax.plot(results.pred_tube_semvec_loss_steps, label=\"planned tube semvec loss\", c=\"C0\")\n",
    "        ax.plot(results.prod_tube_semvec_loss_steps, label=\"produced tube semvec loss\", c=\"C1\")\n",
    "        ax.legend()\n",
    "        fig.savefig(f\"{save_file}_loss_tube_semvec.png\")\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    # save cps\n",
    "    # Vocal Tract CPs   \n",
    "    fig, ax = plt.subplots(facecolor=\"white\", figsize=(15, 10))\n",
    "    colors = [\"C%d\" % i for i in range(19)]\n",
    "\n",
    "    for i in range(4):\n",
    "        ax.plot(results.planned_cp[:, i], color=colors[i], ls = 'solid', lw = 2)\n",
    "        ax.plot(results.initial_cp[:, i], color=colors[i], ls = 'dotted', lw = 4)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], color='black', ls=\"solid\", lw=2, label='Planned Cp'),#\n",
    "                       Line2D([0], [0], color='black',ls =\"dotted\", lw = 4 , label='Inital CP')]\n",
    "\n",
    "    ax.set_ylim((-1.1, 1.1))\n",
    "    plt.legend(handles=legend_elements, fontsize=fontsize_params, bbox_to_anchor=(1.0, 1),frameon = False) \n",
    "    ax.tick_params(axis='both', labelsize=fontsize_params)\n",
    "    ax.set_ylabel('Normalized Position' , fontsize=fontsize_y, labelpad=20)\n",
    "    ax.set_xlabel('Timestep (2.5ms)' , fontsize=fontsize_x, labelpad=20)  \n",
    "    plt.title(\"Vocal Tract Cps: '%s'\" % save_file.split(\"/\")[-1], fontsize=18, pad=10)\n",
    "    fig.savefig(f\"{save_file}_vocal_tract_cps.png\")\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    # Glottis CPs\n",
    "    fig, ax = plt.subplots(facecolor=\"white\", figsize=(15, 10))\n",
    "    colors = [\"C%d\" % i for i in range(19)]\n",
    "\n",
    "    for i in range(4):\n",
    "        ax.plot(results.planned_cp[:, 19+i], color=colors[i], ls = 'solid', lw = 2)\n",
    "        ax.plot(results.initial_cp[:, 19+i], color=colors[i], ls = 'dotted', lw = 4)\n",
    "\n",
    "    legend_elements = [Line2D([0], [0], color='black', ls=\"solid\", lw=2, label='Planned Cp'),#\n",
    "                       Line2D([0], [0], color='black',ls =\"dotted\", lw = 4 , label='Inital CP')]\n",
    "\n",
    "    ax.set_ylim((-1.1, 1.1))\n",
    "    plt.legend(handles=legend_elements, fontsize=fontsize_params, bbox_to_anchor=(1.0, 1),frameon = False) \n",
    "    ax.tick_params(axis='both', labelsize=fontsize_params)\n",
    "    ax.set_ylabel('Normalized Position' , fontsize=fontsize_y, labelpad=20)\n",
    "    ax.set_xlabel('Timestep (2.5ms)' , fontsize=fontsize_x, labelpad=20)\n",
    "    plt.title(\"Glottis Cps: '%s'\" % save_file.split(\"/\")[-1], fontsize=18, pad=10)\n",
    "    fig.savefig(f\"{save_file}_glottis_cps.png\")\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store final losses to txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "with open(SAVE_DICT + '/results_loss.txt', 'w') as txt:\n",
    "    first_row = True\n",
    "    for dic in os.listdir(SAVE_DICT):\n",
    "        if \".DS_Store\" in dic:\n",
    "            continue\n",
    "        else:\n",
    "            path = os.path.join(SAVE_DICT,dic)\n",
    "            if os.path.isdir(path):\n",
    "                for file in os.listdir(path):\n",
    "                    if \".pkl\" in file and \"best_synthesis\" not in file: \n",
    "                        with open(os.path.join(path,file), 'rb') as f:\n",
    "                            results = pickle.load(f)\n",
    "                            file_name = \"_\".join(file.split(\"_\")[:-1])\n",
    "                            loss = results.planned_loss_steps[-1]\n",
    "                            prod_mel_loss = results.prod_loss_steps[-1]\n",
    "                            pred_mel_loss = results.planned_mel_loss_steps[-1]\n",
    "                            vel_loss = results.vel_loss_steps[-1]\n",
    "                            jerk_loss = results.jerk_loss_steps[-1]\n",
    "                            \n",
    "                            prod_semvec_loss = results.prod_semvec_loss_steps[-1]\n",
    "                            pred_semvec_loss = results.pred_semvec_loss_steps[-1] \n",
    "                            if hasattr(results, \"prod_tube_loss_steps\"):\n",
    "                                prod_tube_loss = results.prod_tube_loss_steps[-1]\n",
    "                                prod_tube_mel_loss = results.prod_tube_mel_loss_steps[-1]\n",
    "                                pred_tube_mel_loss = results.pred_tube_mel_loss_steps[-1]\n",
    "                                prod_tube_semvec_loss = results.prod_tube_semvec_loss_steps[-1]\n",
    "                                pred_tube_semvec_loss = results.pred_tube_semvec_loss_steps[-1]\n",
    "                        file_names.append(file_name)    \n",
    "                        if first_row:\n",
    "                            header = \"filename prod_mel_loss pred_mel_loss vel_loss jerk_loss prod_semvec_loss pred_semvec_loss\"\n",
    "                            if hasattr(results, 'prod_tube_loss_steps'):\n",
    "                                txt.write(header + \" prod_tube_loss prod_tube_mel_loss pred_tube_mel_loss prod_tube_semvec_loss pred_tube_semvec_loss\\n\") \n",
    "                            else:\n",
    "                                txt.write(header +\"\\n\")\n",
    "                            first_row = False\n",
    "                        if hasattr(results, 'prod_tube_loss_steps'):\n",
    "                            txt.write(file_name + \" %.5f %.5f %.5f %.5f %.5f %.5f %.5f %.5f %.5f %.5f %.5f\\n\" % (prod_mel_loss, pred_mel_loss, vel_loss, jerk_loss, prod_semvec_loss, pred_semvec_loss, prod_tube_loss, prod_tube_mel_loss, pred_tube_mel_loss, prod_tube_semvec_loss, pred_tube_semvec_loss))\n",
    "                        else:    \n",
    "                            txt.write(file_name + \" %.5f %.5f %.5f %.5f %.5f %.5f\\n\" % (prod_mel_loss, pred_mel_loss, vel_loss, jerk_loss, prod_semvec_loss, pred_semvec_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Model Loss for continued learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_loss = []\n",
    "inv_model_loss = []\n",
    "tube_model_loss = []\n",
    "\n",
    "for dic in os.listdir(SAVE_DICT):\n",
    "    if \".DS_Store\" in dic:\n",
    "        continue\n",
    "    else:\n",
    "        path = os.path.join(SAVE_DICT,dic)\n",
    "        if os.path.isdir(path):\n",
    "            for file in os.listdir(path):\n",
    "                if \".pkl\" in file and \"best_synthesis\" not in file: \n",
    "                    with open(os.path.join(path,file), 'rb') as f:\n",
    "                        results = pickle.load(f)\n",
    "                        pred_model_loss.append(results.pred_model_loss)\n",
    "                        if hasattr(results, \"inv_model_loss\"):\n",
    "                            inv_model_loss.append(results.inv_model_loss)\n",
    "                        if hasattr(results, \"tube_model_loss\"):\n",
    "                            tube_model_loss.append(results.tube_model_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8), facecolor = \"white\")\n",
    "ax.plot(np.array(pred_model_loss).flatten(), label = \"pred_model loss\", c = \"C0\")\n",
    "#ax.plot(range(len(model_loss)),np.repeat(np.mean(model_loss),len(model_loss)) ,c = \"C1\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_pickle(DATA_DIR + \"lexical_embedding_vectors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 0\n",
    "for dic in os.listdir(SAVE_DICT):\n",
    "    if \".DS_Store\" in dic:\n",
    "        continue\n",
    "    else:\n",
    "        path = os.path.join(SAVE_DICT,dic)\n",
    "        if os.path.isdir(path):\n",
    "            for file in os.listdir(path):\n",
    "                if \".pkl\" in file and \"best_synthesis\" not in file: \n",
    "                    label = dic\n",
    "                    target_semvec = vectors[vectors.label == label].iloc[0].vector\n",
    "                    with open(os.path.join(path,file), 'rb') as f:\n",
    "                        results = pickle.load(f)\n",
    "                        file_name = \"_\".join(file.split(\"_\")[:-1])\n",
    "                        planned_cp = results.planned_cp\n",
    "                        initial_cp = results.initial_cp\n",
    "                        initial_sig = results.initial_sig\n",
    "                        initial_prod_mel = results.initial_prod_mel\n",
    "                        initial_pred_mel = results.initial_pred_mel\n",
    "                        target_sig = results.target_sig\n",
    "                        target_sr = results.target_sr\n",
    "                        target_mel = results.target_mel\n",
    "                        prod_sig = results.prod_sig\n",
    "                        prod_sr = results.prod_sr \n",
    "                        prod_mel = results.prod_mel\n",
    "                        pred_mel = results.pred_mel\n",
    "                        initial_prod_semvec = results.initial_prod_semvec\n",
    "                        initial_pred_semvec = results.initial_pred_semvec\n",
    "                        prod_semvec = results.prod_semvec\n",
    "                        pred_semvec = results.pred_semvec                      \n",
    "                        prod_mel_loss = results.prod_loss_steps\n",
    "                        planned_loss = results.planned_loss_steps\n",
    "                        planned_mel_loss = results.planned_mel_loss_steps\n",
    "                        vel_loss = results.vel_loss_steps\n",
    "                        jerk_loss = results.jerk_loss_steps\n",
    "                        prod_semvec_loss = results.prod_semvec_loss_steps\n",
    "                        pred_semvec_loss = results.pred_semvec_loss_steps\n",
    "                        prod_semvec_steps = results.prod_semvec_steps \n",
    "                        pred_semvec_steps = results.pred_semvec_steps\n",
    "                        pred_model_loss = results.pred_model_loss\n",
    "\n",
    "                        if hasattr(results, \"inv_model_loss\"):\n",
    "                            inv_model_loss = results.inv_model_loss\n",
    "\n",
    "                        if hasattr(results, \"tube_model_loss\"):\n",
    "                            initial_prod_tube = results.initial_prod_tube \n",
    "                            initial_pred_tube = results.initial_pred_tube \n",
    "                            initial_prod_tube_mel = results.initial_prod_tube_mel\n",
    "                            initial_pred_tube_mel = results.initial_pred_tube_mel\n",
    "                            prod_tube = results.prod_tube\n",
    "                            pred_tube = results.pred_tube\n",
    "                            prod_tube_mel = results.prod_tube_mel\n",
    "                            pred_tube_mel = results.pred_tube_mel\n",
    "                            initial_prod_tube_semvec = results.initial_prod_tube_semvec\n",
    "                            initial_pred_tube_semvec = results.initial_pred_tube_semvec\n",
    "                            prod_tube_semvec = results.prod_tube_semvec\n",
    "                            pred_tube_semvec = results.pred_tube_semvec\n",
    "                            prod_tube_loss = results.prod_tube_loss_steps\n",
    "                            pred_tube_mel_loss = results.pred_tube_mel_loss_steps\n",
    "                            prod_tube_mel_loss = results.prod_tube_mel_loss_steps\n",
    "                            pred_tube_semvec_loss = results.pred_tube_semvec_loss_steps\n",
    "                            prod_tube_semvec_loss = results.prod_tube_semvec_loss_steps\n",
    "                            prod_tube_semvec_steps = results.prod_tube_semvec_steps\n",
    "                            pred_tube_semvec_steps = results.pred_tube_semvec_steps\n",
    "                            tube_model_loss = results.tube_model_loss\n",
    "\n",
    "                        f.close()\n",
    "\n",
    "                        if ix == 0:\n",
    "                            columns = ['file_name','label', 'planned_cp', 'initial_cp', \n",
    "                                                  'initial_sig','initial_prod_mel', 'initial_pred_mel', \n",
    "                                                  'target_sig', 'target_sr','target_mel',\n",
    "                                                  'prod_sig','prod_sr','prod_mel', 'pred_mel', \n",
    "                                                  'initial_prod_semvec', 'initial_pred_semvec',\n",
    "                                                  'target_semvec',\n",
    "                                                  'prod_semvec', 'pred_semvec',\n",
    "                                                  'prod_mel_loss', 'planned_loss', 'planned_mel_loss', 'vel_loss', 'jerk_loss',\n",
    "                                                  'prod_semvec_loss', 'pred_semvec_loss',\n",
    "                                                  'prod_semvec_steps', 'pred_semvec_steps',\n",
    "                                                  'pred_model_loss']\n",
    "                            \n",
    "                            if hasattr(results, \"inv_model_loss\"):\n",
    "                                columns += [\"inv_model_loss\"]\n",
    "\n",
    "                            if hasattr(results, \"tube_model_loss\"):\n",
    "                                columns += [\"initial_prod_tube\", \"initial_pred_tube\", \"initial_prod_tube_mel\",\"initial_pred_tube_mel\",\n",
    "                                            \"prod_tube\", \"pred_tube\", \"prod_tube_mel\", \"pred_tube_mel\", \n",
    "                                             \"initial_prod_tube_semvec\", \"initial_pred_tube_semvec\", \n",
    "                                            \"prod_tube_semvec\", \"pred_tube_semvec\", \"prod_tube_loss\", \n",
    "                                            \"pred_tube_mel_loss\", \"prod_tube_mel_loss\", \"pred_tube_semvec_loss\",\n",
    "                                            \"prod_tube_semvec_loss\", \"prod_tube_semvec_steps\", \"pred_tube_semvec_steps\", \"tube_model_loss\"]\n",
    " \n",
    "                            \n",
    "                            final_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "                    \n",
    "                        data = [file_name, label, planned_cp, initial_cp , \n",
    "                                initial_sig, initial_prod_mel, initial_pred_mel, \n",
    "                                target_sig, target_sr, target_mel,\n",
    "                                prod_sig, prod_sr, prod_mel, pred_mel, \n",
    "                                initial_prod_semvec, initial_pred_semvec,\n",
    "                                target_semvec, prod_semvec, pred_semvec,\n",
    "                                prod_mel_loss, planned_loss, planned_mel_loss, \n",
    "                                vel_loss, jerk_loss, prod_semvec_loss, pred_semvec_loss,\n",
    "                                prod_semvec_steps, pred_semvec_steps, pred_model_loss]\n",
    "                            \n",
    "                        if hasattr(results, \"inv_model_loss\"):\n",
    "                            data += [inv_model_loss]\n",
    "\n",
    "                        if hasattr(results, \"tube_model_loss\"):\n",
    "                            data += [initial_prod_tube, initial_pred_tube, initial_prod_tube_mel,initial_pred_tube_mel,\n",
    "                                     prod_tube, pred_tube, prod_tube_mel, pred_tube_mel, \n",
    "                                     initial_prod_tube_semvec, initial_pred_tube_semvec, \n",
    "                                     prod_tube_semvec, pred_tube_semvec, prod_tube_loss, \n",
    "                                     pred_tube_mel_loss, prod_tube_mel_loss, pred_tube_semvec_loss,\n",
    "                                     prod_tube_semvec_loss, prod_tube_semvec_steps, pred_tube_semvec_steps, tube_model_loss]\n",
    "            \n",
    "                        final_results.loc[ix] = data\n",
    "                        ix+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_pickle(SAVE_DICT+\"/final_results.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all individual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dic in os.listdir(SAVE_DICT):\n",
    "    if \".DS_Store\" in dic:\n",
    "        continue\n",
    "    else:\n",
    "        path = os.path.join(SAVE_DICT,dic)\n",
    "        if os.path.isdir(path):\n",
    "            for file in os.listdir(path):\n",
    "                if \".pkl\" in file: \n",
    "                    os.remove(os.path.join(path,file))\n",
    "                if \".pt\" in file:\n",
    "                    if not int(file.split(\"_\")[-3]) == (len(final_results)-1):\n",
    "                        os.remove(os.path.join(path,file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
