{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paule/anaconda3/envs/bonn17/lib/python3.8/site-packages/tqdm/std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import paule\n",
    "import utils\n",
    "from utils import speak, normalize_cp, inv_normalize_cp, normalize_mel_librosa, inv_normalize_mel_librosa, stereo_to_mono, librosa_melspec, pad_same_to_even_seq_length, RMSELoss, mel_to_sig\n",
    "from model_zoo import *\n",
    "from training import pad_batch_online\n",
    "from matplotlib import cm\n",
    "DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Volumes/T7/Common_Voice/data/\"\n",
    "RESULT_DICT = \"/Volumes/T7/Common_Voice/common_voice_test_planning\"\n",
    "SAVE_DICT = \"/Volumes/T7/Common_Voice/common_voice_test_planning/results_acoustic_lr_001_lr_model_00001_10_outer_50_inner_6_batches_2_epochs_only_new\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Paule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paule_model = paule.Paule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle(DATA_DIR + \"common_voice_geco_words_test_subset_slim_prot4.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flac Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i,row in test_data.iterrows():\n",
    "    sr = 48000\n",
    "    sig = row.wav_rec\n",
    "    file_name = row.file_name\n",
    "    label = row.label\n",
    "    \n",
    "    path = RESULT_DICT + label + \"/\"\n",
    "    if os.path.isdir(path):\n",
    "        file = path +  file_name + \"_\" + label + \".flac\"\n",
    "        if file.is_file():\n",
    "            j = 1\n",
    "            while file.is_file(): \n",
    "                file = path +  file_name + \"_\" + label + \"%d.flac\" % j\n",
    "                j+=1\n",
    "        sf.write(path +  file_name + \"_\" + label + \"3.flac\" ,sig, sr)\n",
    "    else:\n",
    "        os.mkdir(path)\n",
    "        sf.write(path +  file_name + \"_\" + label + \".flac\" ,sig, sr)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shuffle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for dic in os.listdir(RESULT_DICT):\n",
    "    if (\".DS_Store\" in dic) or (\"results\" in dic) : # .DS_Store stores custom attributes of its containing folder in macOS\n",
    "        continue\n",
    "    else:\n",
    "        if not os.path.isdir(os.path.join(SAVE_DICT,dic)):\n",
    "            os.mkdir(os.path.join(SAVE_DICT,dic))\n",
    "        path = os.path.join(RESULT_DICT,dic)\n",
    "        for file in os.listdir(path):\n",
    "            if (\".DS_Store\" in file) or (\"._\" in file):\n",
    "                continue\n",
    "            else:\n",
    "                file = os.path.join(path,file)\n",
    "                files.append(file)\n",
    "random.seed(30112021)\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omit already planned files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_planned_files = []\n",
    "for dic in os.listdir(SAVE_DICT):\n",
    "    if \".DS_Store\" in dic:\n",
    "        continue\n",
    "    else:\n",
    "        path = os.path.join(SAVE_DICT,dic)\n",
    "        if os.path.isdir(path):\n",
    "            for file in os.listdir(path):\n",
    "                if \"planned\" in file: \n",
    "                    planned_file = \"_\".join(file.split(\"_\")[:-1]) + \".flac\" \n",
    "                    already_planned_files.append(planned_file)\n",
    "\n",
    "unplanned_files = [file for file in files if file.split(\"/\")[-1] not in already_planned_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predictive model already used and further learned during planning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_DICT + '/pred_model_50.pkl', 'rb') as pfile:\n",
    "    model, optimizer = pickle.load(pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paule_model.pred_model = model\n",
    "paule_model.pred_optimizer = optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Planning and store results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,file in enumerate(unplanned_files):\n",
    "    i += 0\n",
    "    target_acoustic = file #path + \"/\" + file\n",
    "    save_file = SAVE_DICT + \"/\" + os.path.dirname(file).split(\"/\")[-1] +\"/\"+os.path.basename(file)[:-5]\n",
    "    results = paule_model.plan_resynth(learning_rate_planning=0.01, learning_rate_learning=0.0001,\n",
    "                         target_acoustic=target_acoustic,\n",
    "                         initialize_from = \"acoustic\",\n",
    "                         objective = \"acoustic\",\n",
    "                         n_outer=10, n_inner=50,\n",
    "                         continue_learning = True,\n",
    "                         add_training_data = False,\n",
    "                         log_ii = 1,\n",
    "                         log_semantics=True,\n",
    "                         n_batches=6, batch_size=8, n_epochs=2,\n",
    "                         log_gradients = False,\n",
    "                         plot=True,plot_save_file=save_file, seed=None,\n",
    "                         verbose=True)\n",
    "\n",
    "    \n",
    "    #save_model\n",
    "    with open(SAVE_DICT + \"/pred_model\" + \"_%d\" % (i) + \".pkl\", \"wb\") as pfile:\n",
    "        m = results[-2]\n",
    "        o = results[-1]\n",
    "        pickle.dump((m, o), pfile)\n",
    "\n",
    "    #save_results\n",
    "    with open(save_file + '.pkl', 'wb') as f:\n",
    "        pickle.dump(results[:-2], f)\n",
    "\n",
    "    # save loss plot\n",
    "    #plot_save_file = path + \"/\" + \"loss_\" + file[:-5] + \".png\"\n",
    "    plot_save_file = SAVE_DICT + \"/\" + os.path.dirname(file).split(\"/\")[-1] + \"/\" + \"loss_\" + os.path.basename(file)[:-5] + \".png\"\n",
    "    prod_loss = results[7]\n",
    "    planned_loss = results[8]\n",
    "    planned_mel_loss = results[9] \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15,8), facecolor = \"white\")\n",
    "    ax.plot(planned_loss, label = \"planned loss\", c=\"C0\")\n",
    "    ax.legend()\n",
    "    fig.savefig(plot_save_file)\n",
    "    \n",
    "    plot_save_file = SAVE_DICT + \"/\" + os.path.dirname(file).split(\"/\")[-1] + \"/\" + \"mel_loss_\" + os.path.basename(file)[:-5] + \".png\"\n",
    "    fig, ax = plt.subplots(figsize = (15,8), facecolor = \"white\")\n",
    "    ax.plot(prod_loss, label = \"produced mel loss\", c = \"C1\")\n",
    "    ax.plot(planned_mel_loss, label = \"planned mel loss\", c=\"C0\")\n",
    "    ax.legend()\n",
    "    fig.savefig(plot_save_file)\n",
    "\n",
    "    # save subloss plot\n",
    "    plot_save_file = SAVE_DICT + \"/\" + os.path.dirname(file).split(\"/\")[-1] + \"/\" + \"subloss_\" + os.path.basename(file)[:-5] + \".png\"\n",
    "    vel_loss = results[10]\n",
    "    jerk_loss = results[11]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (15,8), facecolor = \"white\")\n",
    "    ax.plot(vel_loss, label = \"vel loss\", c = \"C2\")\n",
    "    ax.plot(jerk_loss, label = \"jerk loss\", c=\"C3\")\n",
    "    ax.legend()\n",
    "    fig.savefig(plot_save_file)\n",
    "\n",
    "    # save semvec loss plot\n",
    "    plot_save_file = SAVE_DICT + \"/\" + os.path.dirname(file).split(\"/\")[-1] + \"/\" + \"semvec_loss_\" + os.path.basename(file)[:-5] + \".png\"\n",
    "    pred_semvec_loss = results[12]\n",
    "    prod_semvec_loss = results[13]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (15,8), facecolor = \"white\")\n",
    "    ax.plot(pred_semvec_loss, label = \"planned semvec loss\", c = \"C0\")\n",
    "    ax.plot(prod_semvec_loss, label = \"produced semvec loss\", c=\"C1\")\n",
    "    ax.legend()\n",
    "    fig.savefig(plot_save_file)\n",
    "\n",
    "    # save inv and planned flac\n",
    "    sigs = results[18]\n",
    "    prod_sr = 44100\n",
    "    sig_inv = sigs[0]\n",
    "    sf.write(save_file + \"_inv.flac\" ,sig_inv, prod_sr)\n",
    "\n",
    "    sig_planned = sigs[-1]\n",
    "    sf.write(save_file + \"_planned.flac\" ,sig_planned, prod_sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Model Loss for continued learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = []\n",
    "for dic in os.listdir(SAVE_DICT):\n",
    "    if \".DS_Store\" in dic:\n",
    "        continue\n",
    "    else:\n",
    "        path = os.path.join(SAVE_DICT,dic)\n",
    "        if os.path.isdir(path):\n",
    "            for file in os.listdir(path):\n",
    "                if \".pkl\" in file: \n",
    "                    with open(os.path.join(path,file), 'rb') as f:\n",
    "                        results = pickle.load(f)\n",
    "                        model_loss += list((np.asarray(results[21][:-1:2]) + np.asarray(results[21][1::2]))/2)#results[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8), facecolor = \"white\")\n",
    "ax.plot(model_loss, label = \"model loss\", c = \"C0\")\n",
    "#ax.plot(range(len(model_loss)),np.repeat(np.mean(model_loss),len(model_loss)) ,c = \"C1\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
